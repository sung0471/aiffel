{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /home/aiffel0049/anaconda3/envs/aiffel/lib/python3.7/site-packages (7.2.0)\n",
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "# PIL 라이브러리가 설치되어 있지 않다면 설치\n",
    "!pip install pillow   \n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "seed_value = 1357\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "from tensorflow.compat import v1 as tf_v1\n",
    "session_conf = tf_v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf_v1.Session(graph=tf_v1.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  ['/home/aiffel0049/aiffel/Exploration/1.rock_scissor_paper/train_full/paper', '/home/aiffel0049/aiffel/Exploration/1.rock_scissor_paper/train_full/rock', '/home/aiffel0049/aiffel/Exploration/1.rock_scissor_paper/train_full/scissors']\n",
      "paper 이미지 resize 완료!\n",
      "rock 이미지 resize 완료!\n",
      "scissors 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path_list = list()\n",
    "dataset_type = 'train_full'\n",
    "dataset_dir = ['paper', 'rock', 'scissors']\n",
    "base_dir = os.getcwd()\n",
    "for dir_name in dataset_dir:\n",
    "    image_dir_path_list.append(base_dir + f\"/{dataset_type}/\" + dir_name)\n",
    "    \n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path_list)\n",
    "\n",
    "image_counts = 0\n",
    "for image_path in image_dir_path_list:\n",
    "    images=glob.glob(image_path + \"/*.jpg\")  \n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img,\"JPEG\")\n",
    "        image_counts += 1\n",
    "\n",
    "    print(f\"{image_path.split('/')[-1]} 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 6300 입니다.\n",
      "x_train_resh shape: (6300, 28, 28, 3)\n",
      "y_train shape: (6300,)\n"
     ]
    }
   ],
   "source": [
    "img_size=28\n",
    "color=3\n",
    "def load_data(img_path_list):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=image_counts   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for i, img_path in enumerate(img_path_list):\n",
    "        for file in glob.iglob(img_path+'/*.jpg'):\n",
    "            img = np.array(Image.open(file),dtype=np.int32)\n",
    "            imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "            labels[idx]=i   # 가위 : 0\n",
    "            idx=idx+1\n",
    "\n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "(x_train, y_train)=load_data(image_dir_path_list)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "x_train_resh = x_train_norm.reshape(-1, img_size, img_size, color)\n",
    "\n",
    "print(\"x_train_resh shape: {}\".format(x_train_resh.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train_norm[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평가데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test_resh shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "use_policy = False\n",
    "if use_policy:\n",
    "    from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rotation_range = 20,\n",
    "        width_shift_range = 0.2,\n",
    "        height_shift_range = 0.2,\n",
    "        shear_range = 0.2,\n",
    "        zoom_range = 0.2,\n",
    "        horizontal_flip = True,\n",
    "        vertical_flip = True,\n",
    "        fill_mode = 'nearest'\n",
    "    )\n",
    "    \n",
    "    train_datagen.fit(x_train_norm)\n",
    "\n",
    "test_image_dir_path_list = list()\n",
    "for dir_name in dataset_dir:\n",
    "    test_image_dir_path_list.append(base_dir + \"/test/\" + dir_name)\n",
    "\n",
    "img_size=28\n",
    "color=3\n",
    "def load_test_data(img_path_list):\n",
    "    # 보 : 0, 바위 : 1, 가위 : 2\n",
    "    number_of_data=300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    #이미지 데이터와 라벨(보 : 0, 바위 : 1, 가위 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for i, img_path in enumerate(img_path_list):\n",
    "        for file in glob.iglob(img_path+'/*.jpg'):\n",
    "            img = np.array(Image.open(file),dtype=np.int32)\n",
    "            imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "            labels[idx]=i   # 보 : 0, 바위 : 1, 가위 : 2\n",
    "            idx=idx+1\n",
    "\n",
    "    print(\"평가데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "(x_test, y_test)=load_test_data(test_image_dir_path_list)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "x_test_resh = x_test_norm.reshape(-1, img_size, img_size, color)\n",
    "\n",
    "print(\"x_test_resh shape: {}\".format(x_test_resh.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 26, 26, 16)        64        \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 26, 26, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 11, 11, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 31,011\n",
      "Trainable params: 30,915\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "197/197 [==============================] - 3s 16ms/step - loss: 0.4615 - accuracy: 0.8106\n",
      "Epoch 2/20\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.1600 - accuracy: 0.9506\n",
      "Epoch 3/20\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.0887 - accuracy: 0.9741\n",
      "Epoch 4/20\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.0503 - accuracy: 0.9854\n",
      "Epoch 5/20\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.0376 - accuracy: 0.9900\n",
      "Epoch 6/20\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.0293 - accuracy: 0.9929\n",
      "Epoch 7/20\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.0238 - accuracy: 0.9941\n",
      "Epoch 8/20\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 0.9944\n",
      "Epoch 9/20\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.0199 - accuracy: 0.9941\n",
      "Epoch 10/20\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 0.9968\n",
      "Epoch 11/20\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 0.9965\n",
      "Epoch 12/20\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.0105 - accuracy: 0.9976\n",
      "Epoch 13/20\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 0.9986\n",
      "Epoch 14/20\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.0087 - accuracy: 0.9981\n",
      "Epoch 15/20\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 0.9983\n",
      "Epoch 16/20\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.0103 - accuracy: 0.9975\n",
      "Epoch 17/20\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.0069 - accuracy: 0.9987\n",
      "Epoch 18/20\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.0065 - accuracy: 0.9987\n",
      "Epoch 19/20\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.0049 - accuracy: 0.9995\n",
      "Epoch 20/20\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.0058 - accuracy: 0.9987\n"
     ]
    }
   ],
   "source": [
    "channel_1 = 16\n",
    "channel_2 = 32\n",
    "dense_channel_1 = 32\n",
    "dense_channel_2 = 16\n",
    "dropout = [0.2, 0.2]\n",
    "total_class = 3\n",
    "batch_size = 128\n",
    "epoch = 20\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, BatchNormalization, ReLU, Flatten, Dropout, Dense\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv2D(channel_1, (3,3), input_shape=(28,28,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Conv2D(channel_2, (3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(dense_channel_1, activation='relu'))\n",
    "model.add(Dropout(dropout[0], seed=seed_value))\n",
    "# model.add(keras.layers.Dense(dense_channel_2, activation='relu'))\n",
    "# model.add(keras.layers.Dropout(dropout[1], seed=seed_value))\n",
    "model.add(Dense(total_class, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(keras.optimizers.Adam(decay=1e-3),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "if use_policy:\n",
    "    model.fit(train_datagen.flow(x_train_resh, y_train, batch_size=batch_size),\n",
    "              steps_per_epoch=len(x_train_resh) / batch_size, epochs=epoch)\n",
    "else:\n",
    "    model.fit(x_train_resh, y_train, epochs=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 1s - loss: 7.3445 - accuracy: 0.5100\n",
      "test_loss: 7.344494819641113 \n",
      "test_accuracy: 0.5099999904632568\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_resh, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - 모든 학습데이터 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 기본\n",
    "\n",
    "<code>channel_1 = 16\n",
    "channel_2 = 32\n",
    "dense_channel_1 = 32\n",
    "total_class = 3\n",
    "epoch = 10</code>\n",
    "\n",
    "<code>10/10 - 2s - loss: 13.3738 - accuracy: 0.4433\n",
    "test_loss: 13.373815536499023 \n",
    "test_accuracy: 0.44333332777023315</code>\n",
    "\n",
    "0.4433, 0.3800\n",
    "\n",
    "### 2. ImageDataGenerator 이용 / batch_size=128 / epoch=50\n",
    "\n",
    "channel_1 = 16\n",
    "channel_2 = 32\n",
    "dense_channel_1 = 32\n",
    "total_class = 3\n",
    "batch_size = 128\n",
    "epoch = 50\n",
    "\n",
    "<code>train_datagen = ImageDataGenerator(\n",
    "        rotation_range = 20,\n",
    "        width_shift_range = 0.2,\n",
    "        height_shift_range = 0.2,\n",
    "        shear_range = 0.2,\n",
    "        zoom_range = 0.2,\n",
    "        horizontal_flip = True,\n",
    "        fill_mode = 'nearest'\n",
    "    )</code>\n",
    "\n",
    "<code>10/10 - 0s - loss: 4.9295 - accuracy: 0.3100\n",
    "test_loss: 4.929497241973877 \n",
    "test_accuracy: 0.3100000023841858</code>\n",
    "\n",
    "### 3. x_train 대신, x_train_norm(지금까지 사용 안함...), vertical_flip=True 추가\n",
    "\n",
    "<code>train_datagen = ImageDataGenerator(\n",
    "        rotation_range = 20,\n",
    "        width_shift_range = 0.2,\n",
    "        height_shift_range = 0.2,\n",
    "        shear_range = 0.2,\n",
    "        zoom_range = 0.2,\n",
    "        horizontal_flip = True,\n",
    "        vertical_flip = True,\n",
    "        fill_mode = 'nearest'\n",
    "    )</code>\n",
    "\n",
    "<code>10/10 - 0s - loss: 373.8586 - accuracy: 0.4867\n",
    "test_loss: 373.8586120605469 \n",
    "test_accuracy: 0.4866666793823242</code>\n",
    "\n",
    "### 4. x_train_norm과 x_test대신, x_train_resh, x_test_resh 사용\n",
    "\n",
    "<code>10/10 - 0s - loss: 3.4082 - accuracy: 0.4300\n",
    "test_loss: 3.408247709274292 \n",
    "test_accuracy: 0.4300000071525574</code>\n",
    "\n",
    "### 5. dropout=0.2 추가 (Dense위에)\n",
    "\n",
    "<code>10/10 - 0s - loss: 2.2492 - accuracy: 0.3600\n",
    "test_loss: 2.2491703033447266 \n",
    "test_accuracy: 0.36000001430511475</code>\n",
    "\n",
    "### 6. BatchNormalization 추가 (Conv2D 밑에)\n",
    "\n",
    "<code>10/10 - 0s - loss: 4.4288 - accuracy: 0.3633\n",
    "test_loss: 4.428811550140381 \n",
    "test_accuracy: 0.3633333444595337</code>\n",
    "\n",
    "### 7. dropout 위치 이동 (Dense 밑에)\n",
    "\n",
    "epoch=50\n",
    "\n",
    "<code>10/10 - 0s - loss: 2.4416 - accuracy: 0.4267\n",
    "test_loss: 2.4416098594665527 \n",
    "test_accuracy: 0.4266666769981384</code>\n",
    "\n",
    "epoch=100\n",
    "\n",
    "<code>10/10 - 0s - loss: 4.7021 - accuracy: 0.4133\n",
    "test_loss: 4.702084541320801 \n",
    "test_accuracy: 0.41333332657814026</code>\n",
    "\n",
    "### 8. generator 제거 / optimizer에 weight decay=1e-3추가\n",
    "\n",
    "epoch=20\n",
    "\n",
    "<code>10/10 - 0s - loss: 10.8282 - accuracy: 0.5133\n",
    "test_loss: 10.828228950500488 \n",
    "test_accuracy: 0.5133333206176758</code>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - 내가 만든 데이터로 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 기본\n",
    "\n",
    "<code>channel_1 = 16\n",
    "channel_2 = 32\n",
    "dense_channel_1 = 32\n",
    "dense_channel_2 = 16\n",
    "total_class = 3\n",
    "epoch = 10</code>\n",
    "\n",
    "<code>10/10 - 0s - loss: 9.2919 - accuracy: 0.2867\n",
    "test_loss: 9.29186725616455 \n",
    "test_accuracy: 0.2866666615009308\n",
    "</code>\n",
    "0.46, 0.4433, 0.39, 0.46, 0.4333\n",
    "\n",
    "### 2. dropout 2개 추가 / epoch=100\n",
    "\n",
    "<code>channel_1 = 16\n",
    "channel_2 = 32\n",
    "dense_channel_1 = 32\n",
    "dropout = [0.2, 0.2]\n",
    "total_class = 3\n",
    "epoch = 100</code>\n",
    "\n",
    "<code>10/10 - 0s - loss: 7.6417 - accuracy: 0.4300\n",
    "test_loss: 7.641697406768799 \n",
    "test_accuracy: 0.4300000071525574</code>\n",
    "\n",
    "0.3, 0.33, 0.36, 0.4533, 0.3433\n",
    "\n",
    "### 3. dropout 1개 추가 / epoch=100\n",
    "\n",
    "<code>channel_1 = 16\n",
    "channel_2 = 32\n",
    "dense_channel_1 = 32\n",
    "dropout = [0.2]\n",
    "total_class = 3\n",
    "epoch = 100</code>\n",
    "\n",
    "<code>10/10 - 0s - loss: 10.6041 - accuracy: 0.4000\n",
    "test_loss: 10.604056358337402 \n",
    "test_accuracy: 0.4000000059604645</code>\n",
    "\n",
    "0.4, 0.4867, 0.38, 0.5767, 0.3267\n",
    "\n",
    "### 4. dropout 1개 추가 / channel 변경 / epoch=50\n",
    "\n",
    "<code>channel_1 = 24\n",
    "channel_2 = 48\n",
    "dense_channel_1 = 48\n",
    "dropout = [0.2]\n",
    "total_class = 3\n",
    "epoch = 50</code>\n",
    "\n",
    "<code>10/10 - 0s - loss: 7.5475 - accuracy: 0.3800\n",
    "test_loss: 7.5474748611450195 \n",
    "test_accuracy: 0.3799999952316284</code>\n",
    "\n",
    "0.38, 0.4267, 0.4933, 0.4367, 0.3467\n",
    "\n",
    "### 4. dropout 1개 추가 / channel 변경 / epoch=50\n",
    "\n",
    "<code>channel_1 = 24\n",
    "channel_2 = 48\n",
    "dense_channel_1 = 48\n",
    "dropout = [0.2]\n",
    "total_class = 3\n",
    "epoch = 50</code>\n",
    "\n",
    "<code>10/10 - 0s - loss: 7.5475 - accuracy: 0.3800\n",
    "test_loss: 7.5474748611450195 \n",
    "test_accuracy: 0.3799999952316284</code>\n",
    "\n",
    "0.38, 0.4267, 0.4933, 0.4367, 0.3467\n",
    "\n",
    "### 5. dropout 2개 추가 / channel 변경 / Dense 하나 추가 / epoch=50\n",
    "\n",
    "<code>channel_1 = 24\n",
    "channel_2 = 48\n",
    "dense_channel_1 = 48\n",
    "dropout = [0.2]\n",
    "total_class = 3\n",
    "epoch = 50</code>\n",
    "\n",
    "<code>10/10 - 0s - loss: 7.5475 - accuracy: 0.3800\n",
    "test_loss: 7.5474748611450195 \n",
    "test_accuracy: 0.3799999952316284</code>\n",
    "\n",
    "0.38, 0.4267, 0.4933, 0.4367, 0.3467\n",
    "\n",
    "### 6. dropout 2개 추가 / channel 변경 2 / Dense 하나 추가 / epoch=50\n",
    "\n",
    "<code>channel_1 = 32\n",
    "channel_2 = 64\n",
    "dense_channel_1 = 64\n",
    "dense_channel_2 = 16\n",
    "dropout = [0.2, 0.2]\n",
    "total_class = 3\n",
    "epoch = 50</code>\n",
    "\n",
    "<code>10/10 - 0s - loss: 5.5355 - accuracy: 0.4900\n",
    "test_loss: 5.535473346710205 \n",
    "test_accuracy: 0.49000000953674316</code>\n",
    "\n",
    "0.49, 0.3233, 0.3267, 0.3067, 0.3667"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
