{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기:  187088\n",
      "Examples: \n",
      " [\"I'll undress you, 'cause you're tired\", 'Cover you as you desire', 'When you fall asleep inside my arms']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "txt_file_path = '/home/aiffel0049/aiffel/Exploration/11.make_sentence/data/lyrics/*'\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt파일을 모두 읽음 -> raw_corpus에 담음\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, 'r') as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "        \n",
    "print('데이터 크기: ', len(raw_corpus))\n",
    "print('Examples: \\n', raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this's is sample sentence . <end>\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()  # 소문자 전환, 띄어쓰기 제거\n",
    "    \n",
    "    sentence = re.sub(r'([?.!,¿])', r' \\1 ', sentence)  # 패턴의 특수문자를 만나면 특수문자 양쪽에 공백을 추가\n",
    "    sentence = re.sub(r'[\" \"]+', ' ', sentence)   # 공백 패턴을 만나면 스페이스 1개로 치환\n",
    "    sentence = re.sub(r'[^a-zA-Z?.!,¿\\']+', \" \", sentence)  # a-zA-Z?.!,¿ 패턴을 제외한 모든 문자(공백문자까지도)를 스페이스 1개로 치환\n",
    "    \n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    sentence = '<start> ' + sentence + ' <end>'  # 이전 스텝에서 본 것처럼 문장 앞뒤로 <start>와 <end>를 단어처럼 붙여 줍니다\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "print(preprocess_sentence(\"This's @_is ;;;sample        sentence.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'll undress you, 'cause you're tired\",\n",
       " 'Cover you as you desire',\n",
       " 'When you fall asleep inside my arms',\n",
       " 'May not have the fancy things',\n",
       " \"But I'll give you everything\",\n",
       " \"You could ever want, it's in my arms So baby tell me yes\",\n",
       " 'And I will give you everything',\n",
       " 'So baby tell me yes',\n",
       " 'And I will be all yours tonight',\n",
       " 'So baby tell me yes']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<start> i'll undress you , 'cause you're tired <end>\",\n",
       " '<start> cover you as you desire <end>',\n",
       " '<start> when you fall asleep inside my arms <end>',\n",
       " '<start> may not have the fancy things <end>',\n",
       " \"<start> but i'll give you everything <end>\",\n",
       " \"<start> you could ever want , it's in my arms so baby tell me yes <end>\",\n",
       " '<start> and i will give you everything <end>',\n",
       " '<start> so baby tell me yes <end>',\n",
       " '<start> and i will be all yours tonight <end>',\n",
       " '<start> so baby tell me yes <end>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence) == 0:\n",
    "        continue\n",
    "    \n",
    "    corpus.append(preprocess_sentence(sentence))\n",
    "\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   95 3211 ...    0    0    0]\n",
      " [   2 1195    7 ...    0    0    0]\n",
      " [   2   42    7 ...    0    0    0]\n",
      " ...\n",
      " [   2   25   71 ...    0    0    0]\n",
      " [   2   38   23 ...    0    0    0]\n",
      " [   2   25   71 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f275cdd6bd0>\n"
     ]
    }
   ],
   "source": [
    "def tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000,\n",
    "        filters=' ',\n",
    "        oov_token='<unk>'\n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    \n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "    \n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "    \n",
    "    print(tensor, tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175986, 15)\n",
      "(175986, 15)\n"
     ]
    }
   ],
   "source": [
    "max_len = 15\n",
    "src_input = tensor[:, :max_len]\n",
    "tgt_input = tensor[:, 1:max_len+1]\n",
    "\n",
    "print(src_input.shape)\n",
    "print(tgt_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input,\n",
    "                                                          tgt_input,\n",
    "                                                          test_size=0.29,\n",
    "                                                          random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train :  (124950, 15)\n",
      "Target Train :  (124950, 15)\n"
     ]
    }
   ],
   "source": [
    "print('Source Train : ', enc_train.shape)\n",
    "print('Target Train : ', dec_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 15), (256, 15)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).shuffle(BUFFER_SIZE)\n",
    "dataset_train = dataset_train.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 15), (256, 15)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val = tf.data.Dataset.from_tensor_slices((enc_val, dec_val)).shuffle(BUFFER_SIZE)\n",
    "dataset_val = dataset_val.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인공지능 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size * 2, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "    \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "model = TextGenerator(VOCAB_SIZE, embedding_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  3072256   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  25174016  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  24590049  \n",
      "=================================================================\n",
      "Total params: 58,083,297\n",
      "Trainable params: 58,083,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build((VOCAB_SIZE, embedding_size))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://datascience.stackexchange.com/questions/10615/number-of-parameters-in-an-lstm-model\n",
    "- param 수\n",
    "\n",
    "        params = dim(W) + dim(V) + dim(U) = 4n(m+n+1)\n",
    "        n = hidden layer 차원\n",
    "        m = input layer 차원\n",
    "        \n",
    "        embedding\n",
    "            params : 3072256\n",
    "            vocab_size : 12001\n",
    "            embedding_size : 256\n",
    "        lstm-1\n",
    "            params : 5246976\n",
    "            input : m=256 \n",
    "            hidden : n=1024\n",
    "            bias : 1\n",
    "        lstm-2\n",
    "            params : 8392704\n",
    "            input : 1024\n",
    "            hidden : 1024\n",
    "            bias : 1\n",
    "        dense\n",
    "            params : 12301025\n",
    "            input : 1024\n",
    "            hidden(output) : 12001\n",
    "            bias : 1            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#fit\n",
    "- fit에서 train, val 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "488/488 [==============================] - 822s 2s/step - loss: 3.4227 - val_loss: 3.0370\n",
      "Epoch 2/10\n",
      "488/488 [==============================] - 196s 401ms/step - loss: 2.8697 - val_loss: 2.7887\n",
      "Epoch 3/10\n",
      "488/488 [==============================] - 194s 398ms/step - loss: 2.5947 - val_loss: 2.6416\n",
      "Epoch 4/10\n",
      "488/488 [==============================] - 195s 400ms/step - loss: 2.3506 - val_loss: 2.5376\n",
      "Epoch 5/10\n",
      "488/488 [==============================] - 208s 426ms/step - loss: 2.1237 - val_loss: 2.4608\n",
      "Epoch 6/10\n",
      "488/488 [==============================] - 208s 427ms/step - loss: 1.9110 - val_loss: 2.4062\n",
      "Epoch 7/10\n",
      "488/488 [==============================] - 194s 398ms/step - loss: 1.7160 - val_loss: 2.3696\n",
      "Epoch 8/10\n",
      "488/488 [==============================] - 191s 391ms/step - loss: 1.5410 - val_loss: 2.3518\n",
      "Epoch 9/10\n",
      "488/488 [==============================] - 197s 404ms/step - loss: 1.3867 - val_loss: 2.3481\n",
      "Epoch 10/10\n",
      "488/488 [==============================] - 204s 417ms/step - loss: 1.2548 - val_loss: 2.3568\n"
     ]
    }
   ],
   "source": [
    "#Loss\n",
    "epochs = 10\n",
    "lr = 2e-3\n",
    "decay = 5e-5\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr, decay=decay)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "history = model.fit(dataset_train, validation_data=dataset_val, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/aiffel0049/aiffel/Exploration/11.make_sentence/models/'\n",
    "val_loss = history['val_loss'][-1]\n",
    "model.save_weights(model_path + 'lstm_' + str(val_loss)[:6] + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.keys())\n",
    "\n",
    "# acc = history['acc']\n",
    "losses = history['loss']\n",
    "# val_acc = history['val_acc']\n",
    "val_loss = history['val_loss']\n",
    "\n",
    "plt.plot(losses, 'b', label='train_loss')\n",
    "plt.plot(val_loss, 'r', label='val_loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence='<start>', max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 일단 텐서로 변환\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index['<end>']\n",
    "    \n",
    "    # 텍스트를 실제로 생성할 때, 루프를 돌면서 단어 하나씩 생성해야 함\n",
    "    while True:\n",
    "        predict = model(test_tensor)\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]  # 우리 모델이 예측한 마지막 단어가 바로 새롭게 생성한 단어가 됨\n",
    "        \n",
    "        # 우리 모델이 새롭게 예측한 단어를 입력 문장의 뒤에 붙여줌\n",
    "        test_tensor = tf.concat([test_tensor, \n",
    "                                tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 우리 모델이 <END>를 예측 or max_len에 도달하지 않았다면, while 루프를 돌며 다음 단어 예측해야 함\n",
    "        if predict_word.numpy()[0] == end_token:\n",
    "            break\n",
    "        if test_tensor.shape[1] >= max_len:\n",
    "            break\n",
    "    \n",
    "    generated = ''\n",
    "    # 생성된 tensor안에 있는 word index를 tokenizer.index_word 사전을 통해 실제 단어로 하나씩 변환\n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + ' '\n",
    "    \n",
    "    return generated  # 이것이 최종적으로 모델이 생성한 자연어 문장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you so much , i love you so much , i love you so much , i '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실험내용"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 기본\n",
    "\n",
    "        embedding_size = 256\n",
    "        hidden_size = 1024\n",
    "        lr=1e-3\n",
    "        \n",
    "        loss: 2.2793 - val_loss: 2.5783\n",
    "\n",
    "        '<start> i love you , i need you <end> '\n",
    "\n",
    "2. embedding_size = 512\n",
    "        \n",
    "        embedding_size = 512\n",
    "        hidden_size = 1024\n",
    "        lr=1e-3\n",
    "\n",
    "        val_loss: 2.5551\n",
    "        \n",
    "        <start> i love you , i love you , i love you , i love <end>\n",
    "\n",
    "3. hidden_size=512\n",
    "        \n",
    "        embedding_size = 256\n",
    "        hidden_size = 512\n",
    "        lr=1e-3\n",
    "\n",
    "        loss: 2.6123 - val_loss: 2.7325\n",
    "        \n",
    "        \"<start> i love you , i don't know what i do <end> \"\n",
    "\n",
    "4. layer node 변경\n",
    "        \n",
    "        embedding_size = 256\n",
    "        hidden_size = 1024, 512 (1, 2 layer)\n",
    "        lr=1e-3\n",
    "        \n",
    "        loss: 2.7151 - val_loss: 2.8008\n",
    "        \n",
    "        \"<start> i love you , i don't know , i don't know , i know \"\n",
    "\n",
    "5. decay = 5e-4\n",
    "\n",
    "        embedding_size = 256\n",
    "        hidden_size = 1024, 512 (1, 2 layer)\n",
    "        lr=1e-3, decay=5e-4\n",
    "\n",
    "        loss: 2.6293 - val_loss: 2.7735\n",
    "        \n",
    "        \"<start> i love you , i don't know what i want <end> \"\n",
    "\n",
    "6. decay = 5e-5\n",
    "        \n",
    "        embedding_size = 256\n",
    "        hidden_size = 1024\n",
    "        lr=1e-3, decay=5e-5\n",
    "\n",
    "        loss: 2.3956 - val_loss: 2.6381\n",
    "        \n",
    "        '<start> i love you , i love you <end> '\n",
    "\n",
    "7. lr=3e-3\n",
    "\n",
    "        embedding_size = 256\n",
    "        hidden_size = 1024\n",
    "        lr=3e-3\n",
    "\n",
    "        loss: 1.8772 - val_loss: 2.4724\n",
    "        \n",
    "        '<start> i love ma little nasty girl <end> '\n",
    "\n",
    "8. lr=3e-3, decay=5e-5\n",
    "\n",
    "        embedding_size = 256\n",
    "        hidden_size = 1024\n",
    "        lr=3e-3, decay=5e-5\n",
    "\n",
    "        loss: 1.2963 - val_loss: 2.3904\n",
    "        \n",
    "        '<start> i love you , i love you <end> '\n",
    "\n",
    "9. layer 3개, lr=3e-3, decay=5e-5\n",
    "\n",
    "        embedding_size = 256\n",
    "        hidden_size = 1024 (3 layer)\n",
    "        lr=3e-3, decay=5e-5\n",
    "        \n",
    "        loss: 2.5328 - val_loss: 2.7627\n",
    "        \n",
    "        \"<start> i love you , i don't wanna , i don't wanna , i don't \"\n",
    "        \n",
    "10. layer 4개, hidden_size=512, lr=3e-3, decay=5e-5\n",
    "\n",
    "        embedding_size = 256\n",
    "        hidden_size = 512 (4 layer)\n",
    "        lr=3e-3, decay=5e-5\n",
    "        \n",
    "        loss: 2.6150 - val_loss: 2.8053\n",
    "        \n",
    "        \"<start> i love you , i don't know what i want <end> \"\n",
    "        \n",
    "11. hidden_size=1024, 2048, lr=3e-3, decay=5e-5\n",
    "\n",
    "        embedding_size = 256\n",
    "        hidden_size = 1024, 2048\n",
    "        lr=3e-3, decay=5e-5\n",
    "        \n",
    "        loss: 1.0288 - val_loss: 2.4507\n",
    "        \n",
    "        '<start> i love you mom , you always be my favorite girl . <end> '\n",
    "        \n",
    "        epoch 6부터 fit\n",
    "\n",
    "12. hidden_size=1024, 2048, lr=2e-3, decay=5e-5\n",
    "\n",
    "        embedding_size = 256\n",
    "        hidden_size = 1024, 2048\n",
    "        lr=3e-3, decay=5e-5\n",
    "        \n",
    "        loss: 1.2548 - val_loss: 2.3568\n",
    "        \n",
    "        '<start> i love you so much , i love you so much , i love you so much , i '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
