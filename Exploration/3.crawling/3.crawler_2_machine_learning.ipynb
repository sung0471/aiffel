{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aiffel0049/aiffel/Exploration/3.crawling/news_data.csv start!\n",
      "news    0\n",
      "code    0\n",
      "dtype: int64\n",
      "중복제거 전 뉴스 기사 수 : 5124\n",
      "중복제거 후 뉴스 기사 수 : 3994\n",
      "    code  count\n",
      "0  IT/과학    903\n",
      "1     사회   1668\n",
      "2  생활/문화   1423\n",
      "\n",
      "/home/aiffel0049/aiffel/Exploration/3.crawling/news_data2.csv start!\n",
      "news    0\n",
      "code    0\n",
      "dtype: int64\n",
      "중복제거 전 뉴스 기사 수 : 3703\n",
      "중복제거 후 뉴스 기사 수 : 2137\n",
      "    code  count\n",
      "0  IT/과학    235\n",
      "1     경제    902\n",
      "2     사회    554\n",
      "3  생활/문화    446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_path_list = [os.getcwd() + '/news_data.csv',\n",
    "                 os.getcwd() + '/news_data2.csv']\n",
    "\n",
    "df_list = list()\n",
    "for csv_path in csv_path_list:\n",
    "    print(f'{csv_path} start!')\n",
    "    df = pd.read_table(csv_path, sep=',')\n",
    "\n",
    "    df['news'] = df['news'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    print(f'중복제거 전 뉴스 기사 수 : {len(df)}')\n",
    "    df.drop_duplicates(subset=['news'], inplace=True)\n",
    "    print(f'중복제거 후 뉴스 기사 수 : {len(df)}')\n",
    "    print(df.groupby('code').size().reset_index(name = 'count'), end='\\n\\n')\n",
    "    \n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 두 dataframe 합치기\n",
    "https://rfriend.tistory.com/256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6131\n",
      "    code  count\n",
      "0  IT/과학   1138\n",
      "1     경제    902\n",
      "2     사회   2222\n",
      "3  생활/문화   1869\n"
     ]
    }
   ],
   "source": [
    "df_full = pd.concat(df_list, axis=0)\n",
    "print(len(df_full))\n",
    "print(df_full.groupby('code').size().reset_index(name = 'count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 형태소 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jvm에러는 java 설치   \n",
    "https://www.digitalocean.com/community/tutorials/how-to-install-java-with-apt-on-ubuntu-18-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab, Hannanum, Kkma, Komoran, Okt\n",
    "\n",
    "mec_token = Mecab()\n",
    "han_token = Hannanum()\n",
    "kkm_token = Kkma()\n",
    "kom_token = Komoran()\n",
    "okt_token = Okt()\n",
    "token_list = {'Mecab': mec_token, \n",
    "              'Hannanum': han_token, \n",
    "              'Kkma': kkm_token,\n",
    "              'Komoran': kom_token,\n",
    "              'Okt': okt_token}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['에','는','은','을','했',\n",
    "             '에게','있','이','의','하',\n",
    "             '한','다','과','때문','할',\n",
    "             '수','무단','따른','및','금지',\n",
    "             '전재','경향신문','기자','는데','가',\n",
    "             '등','들','파이낸셜','저작','등','뉴스']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(token: [Mecab, Hannanum, Kkma, Komoran, Okt], data):\n",
    "    text_data = list()\n",
    "    \n",
    "    for sentence in data:\n",
    "        temp_data = token.morphs(sentence)\n",
    "        temp_data = [word for word in temp_data if not word in stopwords]\n",
    "        text_data.append(temp_data)\n",
    "    \n",
    "    text_data = list(map(' '.join, text_data))\n",
    "    \n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6131\n",
      "6131\n",
      "6131\n",
      "6131\n",
      "6131\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "\n",
    "if not os.path.isdir('preprocessing_data'):\n",
    "    os.mkdir('preprocessing_data')\n",
    "\n",
    "text_data_list = dict()\n",
    "preprocessing_time = dict()\n",
    "for token_name, token in token_list.items():\n",
    "    preprocessing_data_path = os.getcwd() + f'/preprocessing_data/{token_name}_data.pkl'\n",
    "    \n",
    "    if os.path.exists(preprocessing_data_path):\n",
    "        text_data = pickle.load(open(preprocessing_data_path, 'rb'))\n",
    "    else:\n",
    "        print(f'{token_name} preprocessing start')\n",
    "        start_time = time.time()\n",
    "        \n",
    "        text_data = preprocessing(token, df_full['news'])\n",
    "        \n",
    "        pickle.dump(text_data, open(preprocessing_data_path, 'wb'))\n",
    "\n",
    "        end_time = time.time() - start_time\n",
    "        preprocessing_time[token_name] = end_time\n",
    "        print('preprocessing time : ', end_time)\n",
    "    \n",
    "    text_data_list[token_name] = text_data\n",
    "    print(len(text_data))\n",
    "\n",
    "import json\n",
    "json_path = os.getcwd() + '/preprocessing_data/preprocessing_time.json'\n",
    "if not os.path.exists(json_path):\n",
    "    json.dump(preprocessing_time, open(json_path, 'wt'), indent=4)\n",
    "else:\n",
    "    preprocessing_time = json.load(open(json_path, 'rt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mecab preprocessing start\n",
    "preprocessing time :  7.921342372894287\n",
    "\n",
    "Hannanum preprocessing start\n",
    "preprocessing time :  210.64576864242554\n",
    "\n",
    "Kkma preprocessing start\n",
    "preprocessing time :  1656.435776233673\n",
    "\n",
    "Komoran preprocessing start\n",
    "preprocessing time :  89.45873713493347\n",
    "\n",
    "Okt preprocessing start\n",
    "preprocessing time :  197.1936264038086"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def show_count_morphs(text_data_list):\n",
    "    morphs_count = dict()\n",
    "    for token_name, data_list in text_data_list.items():\n",
    "        print(f\"{token_name}'s data counting start\")\n",
    "        for data in data_list:\n",
    "            morphs = data.split()\n",
    "            for morph in morphs:\n",
    "                if morph not in morphs_count:\n",
    "                    morphs_count[morph] = 1\n",
    "                else:\n",
    "                    morphs_count[morph] += 1\n",
    "    \n",
    "    reverse_sorted_list = OrderedDict(sorted(morphs_count.items(), key=lambda t: t[1], reverse=True))\n",
    "    sorted_list = OrderedDict(sorted(morphs_count.items(), key=lambda t: t[1]))\n",
    "    return reverse_sorted_list, sorted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mecab's data counting start\n",
      "Hannanum's data counting start\n",
      "Kkma's data counting start\n",
      "Komoran's data counting start\n",
      "Okt's data counting start\n",
      "['ㄴ', '를', '고', '으로', '어', '에서', '로', '되', '도', '었', 'ㄹ', '일', '것', '아', '와', '지', '기', '았', '적', '게']\n",
      "['코로나다', '어지러운', '스트로스', '박혔', '이용균', '참교', '설대우', '왕자서', '마운트배튼', '광천', '전태', '향해야', '모군', '파흐', '다고들', '박홍두', '새빨개', '달집', '시윤', '정창원']\n"
     ]
    }
   ],
   "source": [
    "many_count_list, few_count_list = show_count_morphs(text_data_list)\n",
    "\n",
    "many_count_stopwords = list(many_count_list)[:20]\n",
    "few_count_stopwords = list(few_count_list)[:20]\n",
    "\n",
    "print(many_count_stopwords)\n",
    "print(few_count_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_preprocessing_by_new_stopwords(text_data_list):\n",
    "    text_data_list_many = dict()\n",
    "    text_data_list_few = dict()\n",
    "    for token_name, text_data in text_data_list.items():\n",
    "        print(f'{token_name} extra preprocessing start')\n",
    "        many_count_preprocessed = list()\n",
    "        few_count_preprocessed = list()\n",
    "        for news_text in text_data:\n",
    "            many_news_text = list()\n",
    "            few_news_text = list()\n",
    "            \n",
    "            morphs = news_text.split()\n",
    "            for morph in morphs:\n",
    "                if morph not in many_count_stopwords:\n",
    "                    many_news_text.append(morph)\n",
    "                if morph not in few_count_stopwords:\n",
    "                    few_news_text.append(morph)\n",
    "            many_count_preprocessed.append(many_news_text)\n",
    "            few_count_preprocessed.append(few_news_text)\n",
    "        \n",
    "        many_count_preprocessed = list(map(' '.join, many_count_preprocessed))\n",
    "        few_count_preprocessed = list(map(' '.join, few_count_preprocessed))\n",
    "        text_data_list_many[token_name] = many_count_preprocessed\n",
    "        text_data_list_few[token_name] = few_count_preprocessed\n",
    "    \n",
    "    return text_data_list_many, text_data_list_few"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mecab extra preprocessing start\n",
      "Hannanum extra preprocessing start\n",
      "Kkma extra preprocessing start\n",
      "Komoran extra preprocessing start\n",
      "Okt extra preprocessing start\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "def train_test(text_data_list):\n",
    "    def tfidf_vectorizer(data):\n",
    "        data_counts = count_vect.transform(data)\n",
    "        data_tfidf = tfidf_transformer.transform(data_counts)\n",
    "        return data_tfidf\n",
    "\n",
    "    for token_name, text_data in text_data_list.items():\n",
    "        #- 훈련 데이터와 테스트 데이터를 분리합니다.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(text_data, df_full['code'], random_state = 0)\n",
    "\n",
    "        print(token_name, ' start')\n",
    "        print('훈련용 뉴스 기사의 개수 :', len(X_train))\n",
    "        print('테스트용 뉴스 기사의 개수 : ', len(X_test))\n",
    "        print('훈련용 레이블의 개수 : ', len(y_train))\n",
    "        print('테스트용 레이블의 개수 : ', len(y_test))\n",
    "\n",
    "        #- 단어의 수를 카운트하는 사이킷런의 카운트벡터라이저입니다.\n",
    "        count_vect = CountVectorizer()\n",
    "        X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "        #- 카운트벡터라이저의 결과로부터 TF-IDF 결과를 얻습니다.\n",
    "        tfidf_transformer = TfidfTransformer()\n",
    "        X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "        #- 나이브 베이즈 분류기를 수행합니다.\n",
    "        #- X_train은 TF-IDF 벡터, y_train은 레이블입니다.\n",
    "        clf = MultinomialNB().fit(X_train_tfidf, y_train) \n",
    "\n",
    "        y_pred = clf.predict(tfidf_vectorizer(X_test))\n",
    "        print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "text_data_list_many, text_data_list_few = extra_preprocessing_by_new_stopwords(text_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mecab  start\n",
      "훈련용 뉴스 기사의 개수 : 4598\n",
      "테스트용 뉴스 기사의 개수 :  1533\n",
      "훈련용 레이블의 개수 :  4598\n",
      "테스트용 레이블의 개수 :  1533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.84      0.75      0.79       279\n",
      "          경제       0.88      0.45      0.59       234\n",
      "          사회       0.72      0.92      0.81       547\n",
      "       생활/문화       0.78      0.76      0.77       473\n",
      "\n",
      "    accuracy                           0.77      1533\n",
      "   macro avg       0.81      0.72      0.74      1533\n",
      "weighted avg       0.78      0.77      0.76      1533\n",
      "\n",
      "Hannanum  start\n",
      "훈련용 뉴스 기사의 개수 : 4598\n",
      "테스트용 뉴스 기사의 개수 :  1533\n",
      "훈련용 레이블의 개수 :  4598\n",
      "테스트용 레이블의 개수 :  1533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.85      0.67      0.75       279\n",
      "          경제       0.89      0.40      0.55       234\n",
      "          사회       0.70      0.91      0.79       547\n",
      "       생활/문화       0.72      0.76      0.74       473\n",
      "\n",
      "    accuracy                           0.74      1533\n",
      "   macro avg       0.79      0.69      0.71      1533\n",
      "weighted avg       0.76      0.74      0.73      1533\n",
      "\n",
      "Kkma  start\n",
      "훈련용 뉴스 기사의 개수 : 4598\n",
      "테스트용 뉴스 기사의 개수 :  1533\n",
      "훈련용 레이블의 개수 :  4598\n",
      "테스트용 레이블의 개수 :  1533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.83      0.73      0.78       279\n",
      "          경제       0.86      0.47      0.60       234\n",
      "          사회       0.73      0.92      0.81       547\n",
      "       생활/문화       0.78      0.77      0.77       473\n",
      "\n",
      "    accuracy                           0.77      1533\n",
      "   macro avg       0.80      0.72      0.74      1533\n",
      "weighted avg       0.78      0.77      0.76      1533\n",
      "\n",
      "Komoran  start\n",
      "훈련용 뉴스 기사의 개수 : 4598\n",
      "테스트용 뉴스 기사의 개수 :  1533\n",
      "훈련용 레이블의 개수 :  4598\n",
      "테스트용 레이블의 개수 :  1533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.84      0.75      0.79       279\n",
      "          경제       0.87      0.45      0.59       234\n",
      "          사회       0.73      0.92      0.81       547\n",
      "       생활/문화       0.78      0.77      0.77       473\n",
      "\n",
      "    accuracy                           0.77      1533\n",
      "   macro avg       0.80      0.72      0.74      1533\n",
      "weighted avg       0.78      0.77      0.76      1533\n",
      "\n",
      "Okt  start\n",
      "훈련용 뉴스 기사의 개수 : 4598\n",
      "테스트용 뉴스 기사의 개수 :  1533\n",
      "훈련용 레이블의 개수 :  4598\n",
      "테스트용 레이블의 개수 :  1533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.85      0.69      0.76       279\n",
      "          경제       0.85      0.41      0.55       234\n",
      "          사회       0.69      0.92      0.79       547\n",
      "       생활/문화       0.76      0.75      0.76       473\n",
      "\n",
      "    accuracy                           0.75      1533\n",
      "   macro avg       0.79      0.69      0.71      1533\n",
      "weighted avg       0.77      0.75      0.74      1533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test(text_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mecab  start\n",
      "훈련용 뉴스 기사의 개수 : 4598\n",
      "테스트용 뉴스 기사의 개수 :  1533\n",
      "훈련용 레이블의 개수 :  4598\n",
      "테스트용 레이블의 개수 :  1533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.83      0.75      0.79       279\n",
      "          경제       0.88      0.45      0.60       234\n",
      "          사회       0.72      0.92      0.81       547\n",
      "       생활/문화       0.78      0.77      0.77       473\n",
      "\n",
      "    accuracy                           0.77      1533\n",
      "   macro avg       0.80      0.72      0.74      1533\n",
      "weighted avg       0.78      0.77      0.76      1533\n",
      "\n",
      "Hannanum  start\n",
      "훈련용 뉴스 기사의 개수 : 4598\n",
      "테스트용 뉴스 기사의 개수 :  1533\n",
      "훈련용 레이블의 개수 :  4598\n",
      "테스트용 레이블의 개수 :  1533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.85      0.68      0.75       279\n",
      "          경제       0.88      0.41      0.56       234\n",
      "          사회       0.70      0.91      0.79       547\n",
      "       생활/문화       0.72      0.76      0.74       473\n",
      "\n",
      "    accuracy                           0.74      1533\n",
      "   macro avg       0.79      0.69      0.71      1533\n",
      "weighted avg       0.76      0.74      0.73      1533\n",
      "\n",
      "Kkma  start\n",
      "훈련용 뉴스 기사의 개수 : 4598\n",
      "테스트용 뉴스 기사의 개수 :  1533\n",
      "훈련용 레이블의 개수 :  4598\n",
      "테스트용 레이블의 개수 :  1533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.83      0.74      0.78       279\n",
      "          경제       0.86      0.47      0.61       234\n",
      "          사회       0.73      0.92      0.81       547\n",
      "       생활/문화       0.77      0.77      0.77       473\n",
      "\n",
      "    accuracy                           0.77      1533\n",
      "   macro avg       0.80      0.72      0.74      1533\n",
      "weighted avg       0.78      0.77      0.76      1533\n",
      "\n",
      "Komoran  start\n",
      "훈련용 뉴스 기사의 개수 : 4598\n",
      "테스트용 뉴스 기사의 개수 :  1533\n",
      "훈련용 레이블의 개수 :  4598\n",
      "테스트용 레이블의 개수 :  1533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.84      0.75      0.79       279\n",
      "          경제       0.87      0.45      0.59       234\n",
      "          사회       0.73      0.92      0.81       547\n",
      "       생활/문화       0.78      0.77      0.77       473\n",
      "\n",
      "    accuracy                           0.77      1533\n",
      "   macro avg       0.80      0.72      0.74      1533\n",
      "weighted avg       0.78      0.77      0.76      1533\n",
      "\n",
      "Okt  start\n",
      "훈련용 뉴스 기사의 개수 : 4598\n",
      "테스트용 뉴스 기사의 개수 :  1533\n",
      "훈련용 레이블의 개수 :  4598\n",
      "테스트용 레이블의 개수 :  1533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.84      0.69      0.76       279\n",
      "          경제       0.85      0.42      0.56       234\n",
      "          사회       0.70      0.92      0.79       547\n",
      "       생활/문화       0.76      0.75      0.75       473\n",
      "\n",
      "    accuracy                           0.75      1533\n",
      "   macro avg       0.79      0.69      0.72      1533\n",
      "weighted avg       0.77      0.75      0.74      1533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test(text_data_list_many)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mecab  start\n",
      "훈련용 뉴스 기사의 개수 : 4598\n",
      "테스트용 뉴스 기사의 개수 :  1533\n",
      "훈련용 레이블의 개수 :  4598\n",
      "테스트용 레이블의 개수 :  1533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.84      0.75      0.79       279\n",
      "          경제       0.88      0.45      0.59       234\n",
      "          사회       0.72      0.92      0.81       547\n",
      "       생활/문화       0.78      0.76      0.77       473\n",
      "\n",
      "    accuracy                           0.77      1533\n",
      "   macro avg       0.81      0.72      0.74      1533\n",
      "weighted avg       0.78      0.77      0.76      1533\n",
      "\n",
      "Hannanum  start\n",
      "훈련용 뉴스 기사의 개수 : 4598\n",
      "테스트용 뉴스 기사의 개수 :  1533\n",
      "훈련용 레이블의 개수 :  4598\n",
      "테스트용 레이블의 개수 :  1533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.85      0.67      0.75       279\n",
      "          경제       0.89      0.40      0.55       234\n",
      "          사회       0.70      0.91      0.79       547\n",
      "       생활/문화       0.72      0.76      0.74       473\n",
      "\n",
      "    accuracy                           0.74      1533\n",
      "   macro avg       0.79      0.69      0.71      1533\n",
      "weighted avg       0.76      0.74      0.73      1533\n",
      "\n",
      "Kkma  start\n",
      "훈련용 뉴스 기사의 개수 : 4598\n",
      "테스트용 뉴스 기사의 개수 :  1533\n",
      "훈련용 레이블의 개수 :  4598\n",
      "테스트용 레이블의 개수 :  1533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.83      0.73      0.78       279\n",
      "          경제       0.86      0.47      0.60       234\n",
      "          사회       0.73      0.92      0.81       547\n",
      "       생활/문화       0.78      0.77      0.77       473\n",
      "\n",
      "    accuracy                           0.77      1533\n",
      "   macro avg       0.80      0.72      0.74      1533\n",
      "weighted avg       0.78      0.77      0.76      1533\n",
      "\n",
      "Komoran  start\n",
      "훈련용 뉴스 기사의 개수 : 4598\n",
      "테스트용 뉴스 기사의 개수 :  1533\n",
      "훈련용 레이블의 개수 :  4598\n",
      "테스트용 레이블의 개수 :  1533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.84      0.75      0.79       279\n",
      "          경제       0.87      0.45      0.59       234\n",
      "          사회       0.73      0.92      0.81       547\n",
      "       생활/문화       0.78      0.77      0.77       473\n",
      "\n",
      "    accuracy                           0.77      1533\n",
      "   macro avg       0.80      0.72      0.74      1533\n",
      "weighted avg       0.78      0.77      0.76      1533\n",
      "\n",
      "Okt  start\n",
      "훈련용 뉴스 기사의 개수 : 4598\n",
      "테스트용 뉴스 기사의 개수 :  1533\n",
      "훈련용 레이블의 개수 :  4598\n",
      "테스트용 레이블의 개수 :  1533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.85      0.69      0.76       279\n",
      "          경제       0.85      0.41      0.55       234\n",
      "          사회       0.69      0.92      0.79       547\n",
      "       생활/문화       0.76      0.75      0.76       473\n",
      "\n",
      "    accuracy                           0.75      1533\n",
      "   macro avg       0.79      0.69      0.71      1533\n",
      "weighted avg       0.77      0.75      0.74      1533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test(text_data_list_few)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  불용어가 30개인 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Mecab  start\n",
    "훈련용 뉴스 기사의 개수 : 4598\n",
    "테스트용 뉴스 기사의 개수 :  1533\n",
    "훈련용 레이블의 개수 :  4598\n",
    "테스트용 레이블의 개수 :  1533\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       IT/과학       0.84      0.75      0.79       279\n",
    "          경제       0.88      0.45      0.59       234\n",
    "          사회       0.72      0.92      0.81       547\n",
    "       생활/문화       0.78      0.76      0.77       473\n",
    "\n",
    "    accuracy                           0.77      1533\n",
    "   macro avg       0.81      0.72      0.74      1533\n",
    "weighted avg       0.78      0.77      0.76      1533\n",
    "\n",
    "Hannanum  start\n",
    "훈련용 뉴스 기사의 개수 : 4598\n",
    "테스트용 뉴스 기사의 개수 :  1533\n",
    "훈련용 레이블의 개수 :  4598\n",
    "테스트용 레이블의 개수 :  1533\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       IT/과학       0.85      0.67      0.75       279\n",
    "          경제       0.89      0.40      0.55       234\n",
    "          사회       0.70      0.91      0.79       547\n",
    "       생활/문화       0.72      0.76      0.74       473\n",
    "\n",
    "    accuracy                           0.74      1533\n",
    "   macro avg       0.79      0.69      0.71      1533\n",
    "weighted avg       0.76      0.74      0.73      1533\n",
    "\n",
    "Kkma  start\n",
    "훈련용 뉴스 기사의 개수 : 4598\n",
    "테스트용 뉴스 기사의 개수 :  1533\n",
    "훈련용 레이블의 개수 :  4598\n",
    "테스트용 레이블의 개수 :  1533\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       IT/과학       0.83      0.73      0.78       279\n",
    "          경제       0.86      0.47      0.60       234\n",
    "          사회       0.73      0.92      0.81       547\n",
    "       생활/문화       0.78      0.77      0.77       473\n",
    "\n",
    "    accuracy                           0.77      1533\n",
    "   macro avg       0.80      0.72      0.74      1533\n",
    "weighted avg       0.78      0.77      0.76      1533\n",
    "\n",
    "Komoran  start\n",
    "훈련용 뉴스 기사의 개수 : 4598\n",
    "테스트용 뉴스 기사의 개수 :  1533\n",
    "훈련용 레이블의 개수 :  4598\n",
    "테스트용 레이블의 개수 :  1533\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       IT/과학       0.84      0.75      0.79       279\n",
    "          경제       0.87      0.45      0.59       234\n",
    "          사회       0.73      0.92      0.81       547\n",
    "       생활/문화       0.78      0.77      0.77       473\n",
    "\n",
    "    accuracy                           0.77      1533\n",
    "   macro avg       0.80      0.72      0.74      1533\n",
    "weighted avg       0.78      0.77      0.76      1533\n",
    "\n",
    "Okt  start\n",
    "훈련용 뉴스 기사의 개수 : 4598\n",
    "테스트용 뉴스 기사의 개수 :  1533\n",
    "훈련용 레이블의 개수 :  4598\n",
    "테스트용 레이블의 개수 :  1533\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       IT/과학       0.85      0.69      0.76       279\n",
    "          경제       0.85      0.41      0.55       234\n",
    "          사회       0.69      0.92      0.79       547\n",
    "       생활/문화       0.76      0.75      0.76       473\n",
    "\n",
    "    accuracy                           0.75      1533\n",
    "   macro avg       0.79      0.69      0.71      1533\n",
    "weighted avg       0.77      0.75      0.74      1533\n",
    "</pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불용어가 50개면서, 가장 카운트 많은 형태소를 불용어로 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Mecab  start\n",
    "훈련용 뉴스 기사의 개수 : 4598\n",
    "테스트용 뉴스 기사의 개수 :  1533\n",
    "훈련용 레이블의 개수 :  4598\n",
    "테스트용 레이블의 개수 :  1533\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       IT/과학       0.83      0.75      0.79       279\n",
    "          경제       0.88      0.45      0.60       234\n",
    "          사회       0.72      0.92      0.81       547\n",
    "       생활/문화       0.78      0.77      0.77       473\n",
    "\n",
    "    accuracy                           0.77      1533\n",
    "   macro avg       0.80      0.72      0.74      1533\n",
    "weighted avg       0.78      0.77      0.76      1533\n",
    "\n",
    "Hannanum  start\n",
    "훈련용 뉴스 기사의 개수 : 4598\n",
    "테스트용 뉴스 기사의 개수 :  1533\n",
    "훈련용 레이블의 개수 :  4598\n",
    "테스트용 레이블의 개수 :  1533\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       IT/과학       0.85      0.68      0.75       279\n",
    "          경제       0.88      0.41      0.56       234\n",
    "          사회       0.70      0.91      0.79       547\n",
    "       생활/문화       0.72      0.76      0.74       473\n",
    "\n",
    "    accuracy                           0.74      1533\n",
    "   macro avg       0.79      0.69      0.71      1533\n",
    "weighted avg       0.76      0.74      0.73      1533\n",
    "\n",
    "Kkma  start\n",
    "훈련용 뉴스 기사의 개수 : 4598\n",
    "테스트용 뉴스 기사의 개수 :  1533\n",
    "훈련용 레이블의 개수 :  4598\n",
    "테스트용 레이블의 개수 :  1533\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       IT/과학       0.83      0.74      0.78       279\n",
    "          경제       0.86      0.47      0.61       234\n",
    "          사회       0.73      0.92      0.81       547\n",
    "       생활/문화       0.77      0.77      0.77       473\n",
    "\n",
    "    accuracy                           0.77      1533\n",
    "   macro avg       0.80      0.72      0.74      1533\n",
    "weighted avg       0.78      0.77      0.76      1533\n",
    "\n",
    "Komoran  start\n",
    "훈련용 뉴스 기사의 개수 : 4598\n",
    "테스트용 뉴스 기사의 개수 :  1533\n",
    "훈련용 레이블의 개수 :  4598\n",
    "테스트용 레이블의 개수 :  1533\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       IT/과학       0.84      0.75      0.79       279\n",
    "          경제       0.87      0.45      0.59       234\n",
    "          사회       0.73      0.92      0.81       547\n",
    "       생활/문화       0.78      0.77      0.77       473\n",
    "\n",
    "    accuracy                           0.77      1533\n",
    "   macro avg       0.80      0.72      0.74      1533\n",
    "weighted avg       0.78      0.77      0.76      1533\n",
    "\n",
    "Okt  start\n",
    "훈련용 뉴스 기사의 개수 : 4598\n",
    "테스트용 뉴스 기사의 개수 :  1533\n",
    "훈련용 레이블의 개수 :  4598\n",
    "테스트용 레이블의 개수 :  1533\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       IT/과학       0.84      0.69      0.76       279\n",
    "          경제       0.85      0.42      0.56       234\n",
    "          사회       0.70      0.92      0.79       547\n",
    "       생활/문화       0.76      0.75      0.75       473\n",
    "\n",
    "    accuracy                           0.75      1533\n",
    "   macro avg       0.79      0.69      0.72      1533\n",
    "weighted avg       0.77      0.75      0.74      1533\n",
    "<pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불용어가 50개면서, 가장 카운트 적은 형태소를 불용어로 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Mecab  start\n",
    "훈련용 뉴스 기사의 개수 : 4598\n",
    "테스트용 뉴스 기사의 개수 :  1533\n",
    "훈련용 레이블의 개수 :  4598\n",
    "테스트용 레이블의 개수 :  1533\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       IT/과학       0.84      0.75      0.79       279\n",
    "          경제       0.88      0.45      0.59       234\n",
    "          사회       0.72      0.92      0.81       547\n",
    "       생활/문화       0.78      0.76      0.77       473\n",
    "\n",
    "    accuracy                           0.77      1533\n",
    "   macro avg       0.81      0.72      0.74      1533\n",
    "weighted avg       0.78      0.77      0.76      1533\n",
    "\n",
    "Hannanum  start\n",
    "훈련용 뉴스 기사의 개수 : 4598\n",
    "테스트용 뉴스 기사의 개수 :  1533\n",
    "훈련용 레이블의 개수 :  4598\n",
    "테스트용 레이블의 개수 :  1533\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       IT/과학       0.85      0.67      0.75       279\n",
    "          경제       0.89      0.40      0.55       234\n",
    "          사회       0.70      0.91      0.79       547\n",
    "       생활/문화       0.72      0.76      0.74       473\n",
    "\n",
    "    accuracy                           0.74      1533\n",
    "   macro avg       0.79      0.69      0.71      1533\n",
    "weighted avg       0.76      0.74      0.73      1533\n",
    "\n",
    "Kkma  start\n",
    "훈련용 뉴스 기사의 개수 : 4598\n",
    "테스트용 뉴스 기사의 개수 :  1533\n",
    "훈련용 레이블의 개수 :  4598\n",
    "테스트용 레이블의 개수 :  1533\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       IT/과학       0.83      0.73      0.78       279\n",
    "          경제       0.86      0.47      0.60       234\n",
    "          사회       0.73      0.92      0.81       547\n",
    "       생활/문화       0.78      0.77      0.77       473\n",
    "\n",
    "    accuracy                           0.77      1533\n",
    "   macro avg       0.80      0.72      0.74      1533\n",
    "weighted avg       0.78      0.77      0.76      1533\n",
    "\n",
    "Komoran  start\n",
    "훈련용 뉴스 기사의 개수 : 4598\n",
    "테스트용 뉴스 기사의 개수 :  1533\n",
    "훈련용 레이블의 개수 :  4598\n",
    "테스트용 레이블의 개수 :  1533\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       IT/과학       0.84      0.75      0.79       279\n",
    "          경제       0.87      0.45      0.59       234\n",
    "          사회       0.73      0.92      0.81       547\n",
    "       생활/문화       0.78      0.77      0.77       473\n",
    "\n",
    "    accuracy                           0.77      1533\n",
    "   macro avg       0.80      0.72      0.74      1533\n",
    "weighted avg       0.78      0.77      0.76      1533\n",
    "\n",
    "Okt  start\n",
    "훈련용 뉴스 기사의 개수 : 4598\n",
    "테스트용 뉴스 기사의 개수 :  1533\n",
    "훈련용 레이블의 개수 :  4598\n",
    "테스트용 레이블의 개수 :  1533\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       IT/과학       0.85      0.69      0.76       279\n",
    "          경제       0.85      0.41      0.55       234\n",
    "          사회       0.69      0.92      0.79       547\n",
    "       생활/문화       0.76      0.75      0.76       473\n",
    "\n",
    "    accuracy                           0.75      1533\n",
    "   macro avg       0.79      0.69      0.71      1533\n",
    "weighted avg       0.77      0.75      0.74      1533\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 세 케이스에 대한 분석 필요"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
