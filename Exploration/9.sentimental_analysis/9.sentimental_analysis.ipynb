{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 워드 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 간단한 사전 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word = {}\n",
    "\n",
    "# 단어를 하나씩 채움 / 순서는 중요치 않음 (임의적으로 채움)\n",
    "# <BOS> <PAD> <UNK>는 관례적으로 맨 앞에 넣어줌\n",
    "index_to_word[0] = '<PAD>' # 패딩용 단어\n",
    "index_to_word[1] = '<BOS>' # 문장의 시작지점\n",
    "index_to_word[2] = '<UNK>' # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3] = 'i'\n",
    "index_to_word[4] = 'feel'\n",
    "index_to_word[5] = 'hungry'\n",
    "index_to_word[6] = 'eat'\n",
    "index_to_word[7] = 'lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어 -> index로 변환하는 사전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "word_to_index = {word:index for index,word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 워드 임베딩하는 함수 (단어 -> 인덱스)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']] + [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence(sentences[1], word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임베딩된 데이터를 디코딩하는 함수 (인덱스 -> 단어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    # [1:]를 통해 <BOS>를 제외\n",
    "    return ' '.join([index_to_word[i] if i in index_to_word else '<UNK>' for i in encoded_sentence[1:]])\n",
    "\n",
    "print(get_decoded_sentence(encoded_sentences[0], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 임베딩 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([1, 3, 4, 5]) list([1, 3, 6, 7]) list([1, 8, 3, 4, 9])]\n",
      "tf.Tensor(\n",
      "[[[ 0.03508003 -0.02779454  0.01927438 -0.03799442]\n",
      "  [-0.03493961  0.0352709   0.00901802 -0.03208896]\n",
      "  [ 0.02145391  0.01827606 -0.00531596  0.04793683]\n",
      "  [-0.00352221  0.0026083  -0.04902512 -0.04734998]\n",
      "  [ 0.03222298  0.01345911  0.00083692  0.02097995]]\n",
      "\n",
      " [[ 0.03508003 -0.02779454  0.01927438 -0.03799442]\n",
      "  [-0.03493961  0.0352709   0.00901802 -0.03208896]\n",
      "  [ 0.03431574  0.03713374  0.00587662 -0.03785485]\n",
      "  [ 0.02475501  0.01369863 -0.02716534 -0.00993086]\n",
      "  [ 0.03222298  0.01345911  0.00083692  0.02097995]]\n",
      "\n",
      " [[ 0.03508003 -0.02779454  0.01927438 -0.03799442]\n",
      "  [ 0.00860394 -0.01189981  0.00104355  0.04844805]\n",
      "  [-0.03493961  0.0352709   0.00901802 -0.03208896]\n",
      "  [ 0.02145391  0.01827606 -0.00531596  0.04793683]\n",
      "  [-0.02784665 -0.01868136 -0.02213362  0.02596934]]], shape=(3, 5, 4), dtype=float32)\n",
      "[[1 3 4 5 0]\n",
      " [1 3 6 7 0]\n",
      " [1 8 3 4 9]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "vocab_size = len(word_to_index) # 단어->인덱스 변환 dict(), len=10\n",
    "word_vector_dim = 4 # 4차원 워드벡터를 만들 예정\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다. \n",
    "# list 형태의 sentences는 numpy array로 변환되어야 딥러닝 레이어의 입력이 될 수 있습니다.\n",
    "\n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "print(raw_inputs)\n",
    "# inputs 길이가 4, 4, 5로 안맞으므로, 벡터 뒤에 PADDING을 넣어줘야함\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)\n",
    "print(raw_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10     # 어휘 사전의 크기(10개 단어) \n",
    "word_vector_dim = 4 # 어휘당 학습하고자 하는 속성(워드 벡터의 차원 수 4개)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))  # 가장 널리 쓰이는 RNN인 LSTM 모델, LSTM 벡터의 차원수 = 8\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) # 긍/부정을 나타내는 1dim\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          448       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1792      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 128       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 8         \n",
      "=================================================================\n",
      "Total params: 2,416\n",
      "Trainable params: 2,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10     # 어휘 사전의 크기(10개 단어) \n",
    "word_vector_dim = 4 # 어휘당 학습하고자 하는 속성(워드 벡터의 차원 수 4개)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu', use_bias=False))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu', use_bias=False))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu', use_bias=False))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid', use_bias=False)) # 최종 출력 = 긍/부정 = 1dim\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global_max_pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB 영화리뷰 감성분석\n",
    "- 25000, 25000 테스트 데이터\n",
    "- 긍정 1, 부정  0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "train samples : 25000, test samples : 25000\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "# IMDB 다운로드\n",
    "# num_words = 10000 : 10000개만큼 word_to_index 까지 생성된 형태로 데이터셋 생성\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"train samples : {}, test samples : {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 리뷰데이터\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "레이블 : 1\n",
      "리뷰 문장 길이 : 218\n",
      "\n",
      "2번째 리뷰데이터\n",
      "[1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n",
      "레이블 : 0\n",
      "리뷰 문장 길이 : 189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print('{}번째 리뷰데이터'.format(i+1))\n",
    "    print('{}\\n'\n",
    "          '레이블 : {}\\n'\n",
    "         '리뷰 문장 길이 : {}'.format(x_train[i], y_train[i], len(x_train[i]))\n",
    "         , end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index: word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])\n",
    "print(word_to_index['the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "# 실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다. \n",
    "word_to_index = {k:v+3 for k, v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "word_to_index['<PAD>'] = 0\n",
    "word_to_index['<BOS>'] = 1\n",
    "word_to_index['<UNK>'] = 2 # unknown\n",
    "word_to_index['<UNUSED'] = 3\n",
    "\n",
    "# 이거 안해도됨\n",
    "# index_to_word[0] = '<PAD>'\n",
    "# index_to_word[1] = '<BOS>'\n",
    "# index_to_word[2] = '<UNK>'\n",
    "# index_to_word[3] = '<UNUSED>'\n",
    "\n",
    "index_to_word = {index :word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])\n",
    "print(word_to_index['the'])\n",
    "print(index_to_word[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "레이블 :  1\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('레이블 : ', y_train[0])  # 1번째 리뷰데이터 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대:  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "fpad_sequences_maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 이내에 포함됨\n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차 계산\n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대: ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를 들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,\n",
    "max_tokens = np.mean(num_tokens) + 2*np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('fpad_sequences_maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 이내에 포함됨'.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다른 방식의 padding : pre, post 둘 중 하나 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, \n",
    "                                                    value=word_to_index['<PAD>'],\n",
    "                                                    padding='post',\n",
    "                                                    maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                   value=word_to_index['<PAD>'],\n",
    "                                                   padding='post',\n",
    "                                                   maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝 모델 설계, 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000 # 어휘 사전 크기\n",
    "word_vector_dim = 16 # 워드 벡터 차원수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Global():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "    model.add(keras.layers.GlobalMaxPooling1D())\n",
    "    model.add(keras.layers.Dense(4096))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.ReLU())\n",
    "    model.add(keras.layers.Dense(1024))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.ReLU())\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cnn():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "    model.add(keras.layers.Conv1D(32, 7, activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling1D(5))\n",
    "    model.add(keras.layers.Conv1D(32, 7, activation='relu'))\n",
    "    model.add(keras.layers.GlobalMaxPooling1D())\n",
    "    model.add(keras.layers.Dense(4096))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.ReLU())\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid')) # 최종 출력 = 긍/부정 = 1dim\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rnn():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "    model.add(keras.layers.LSTM(16))  # 가장 널리 쓰이는 RNN인 LSTM 모델, LSTM 벡터의 차원수 = 8\n",
    "    model.add(keras.layers.Dense(4096))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.ReLU())\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid')) # 긍/부정을 나타내는 1dim\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 32)          3616      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 32)          7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4096)              135168    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 310,081\n",
      "Trainable params: 310,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model 설계\n",
    "model_select = {'global': Global, 'cnn': Cnn, 'rnn': Rnn}\n",
    "\n",
    "model = model_select['cnn']()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "x_val = x_train[:10000]\n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation 제외한 나머지\n",
    "partial_x_train = x_train[10000:]\n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 8s 253ms/step - loss: 0.6934 - accuracy: 0.5038 - val_loss: 0.6929 - val_accuracy: 0.4974\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6732 - accuracy: 0.5966 - val_loss: 0.5772 - val_accuracy: 0.7323\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.3934 - accuracy: 0.8325 - val_loss: 0.3231 - val_accuracy: 0.8651\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.2095 - accuracy: 0.9192 - val_loss: 0.3141 - val_accuracy: 0.8690\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.1181 - accuracy: 0.9620 - val_loss: 0.3528 - val_accuracy: 0.8716\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.0646 - accuracy: 0.9837 - val_loss: 0.4064 - val_accuracy: 0.8685\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0294 - accuracy: 0.9953 - val_loss: 0.5044 - val_accuracy: 0.8657\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0146 - accuracy: 0.9983 - val_loss: 0.5478 - val_accuracy: 0.8618\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.0067 - accuracy: 0.9993 - val_loss: 0.5989 - val_accuracy: 0.8617\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.6410 - val_accuracy: 0.8612\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.6788 - val_accuracy: 0.8614\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 8.2914e-04 - accuracy: 1.0000 - val_loss: 0.7089 - val_accuracy: 0.8608\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 5.9477e-04 - accuracy: 1.0000 - val_loss: 0.7337 - val_accuracy: 0.8610\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 4.4769e-04 - accuracy: 1.0000 - val_loss: 0.7598 - val_accuracy: 0.8610\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 3.5436e-04 - accuracy: 1.0000 - val_loss: 0.7774 - val_accuracy: 0.8609\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 2.8386e-04 - accuracy: 1.0000 - val_loss: 0.7950 - val_accuracy: 0.8608\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 2.3377e-04 - accuracy: 1.0000 - val_loss: 0.8118 - val_accuracy: 0.8612\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 1.9703e-04 - accuracy: 1.0000 - val_loss: 0.8278 - val_accuracy: 0.8607\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 1.6526e-04 - accuracy: 1.0000 - val_loss: 0.8437 - val_accuracy: 0.8608\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 1.4006e-04 - accuracy: 1.0000 - val_loss: 0.8576 - val_accuracy: 0.8612\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=epochs,\n",
    "                   batch_size=512,\n",
    "                   validation_data=(x_val, y_val),\n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 3s - loss: 0.9558 - accuracy: 0.8478\n",
      "[0.9558389782905579, 0.8478000164031982]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# 'bo'는 파란색 점\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 파란 실선\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Traning acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 워드 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 학습한 embedding 파라미터 > 파일에 저장\n",
    "word2vec_file_path = '/home/aiffel0049/aiffel/Exploration/9.sentimental_analysis/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim)) # 몇개 벡터를 얼마 사이즈로 기재할지 타이틀 작성\n",
    "\n",
    "# 단어 개수(에서 4개 제외)만큼의 워드 벡터를 파일에 기록\n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4, vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03093542,  0.01461959, -0.02924525,  0.03354142,  0.02887502,\n",
       "       -0.00594641, -0.01231226,  0.0049962 , -0.04515434, -0.01782604,\n",
       "        0.00051902, -0.05382626, -0.00673995,  0.04378683,  0.04239551,\n",
       "        0.05461605], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vision', 0.8693547248840332),\n",
       " ('cheering', 0.839249849319458),\n",
       " ('rates', 0.8224093317985535),\n",
       " ('luck', 0.7935540676116943),\n",
       " ('fuller', 0.779646635055542),\n",
       " ('awe', 0.775079071521759),\n",
       " ('artistically', 0.7737942337989807),\n",
       " ('glorious', 0.768541693687439),\n",
       " ('presentation', 0.7660696506500244),\n",
       " ('liberties', 0.7630019187927246)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word('love')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec_path = '/home/aiffel0049/aiffel/Exploration/9.sentimental_analysis/data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow import keras\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 24s 807ms/step - loss: 0.6937 - accuracy: 0.5118 - val_loss: 0.6923 - val_accuracy: 0.5267\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 7s 218ms/step - loss: 0.6803 - accuracy: 0.5661 - val_loss: 0.6675 - val_accuracy: 0.5950\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 7s 217ms/step - loss: 0.6242 - accuracy: 0.6590 - val_loss: 0.5843 - val_accuracy: 0.7100\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 6s 211ms/step - loss: 0.4848 - accuracy: 0.7854 - val_loss: 0.4280 - val_accuracy: 0.8129\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 6s 211ms/step - loss: 0.3303 - accuracy: 0.8678 - val_loss: 0.3431 - val_accuracy: 0.8542\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 6s 216ms/step - loss: 0.2320 - accuracy: 0.9136 - val_loss: 0.3183 - val_accuracy: 0.8662\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 7s 221ms/step - loss: 0.1654 - accuracy: 0.9466 - val_loss: 0.3173 - val_accuracy: 0.8670\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 7s 219ms/step - loss: 0.1261 - accuracy: 0.9635 - val_loss: 0.3204 - val_accuracy: 0.8680\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 7s 224ms/step - loss: 0.0879 - accuracy: 0.9799 - val_loss: 0.3311 - val_accuracy: 0.8689\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.0632 - accuracy: 0.9879 - val_loss: 0.3740 - val_accuracy: 0.8597\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 6s 214ms/step - loss: 0.0499 - accuracy: 0.9921 - val_loss: 0.3617 - val_accuracy: 0.8657\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 6s 211ms/step - loss: 0.0299 - accuracy: 0.9975 - val_loss: 0.3749 - val_accuracy: 0.8660\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 6s 211ms/step - loss: 0.0207 - accuracy: 0.9991 - val_loss: 0.3871 - val_accuracy: 0.8660\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 7s 222ms/step - loss: 0.0155 - accuracy: 0.9992 - val_loss: 0.3983 - val_accuracy: 0.8661\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 6s 210ms/step - loss: 0.0120 - accuracy: 0.9993 - val_loss: 0.4162 - val_accuracy: 0.8641\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 6s 208ms/step - loss: 0.0093 - accuracy: 0.9994 - val_loss: 0.4256 - val_accuracy: 0.8653\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 6s 209ms/step - loss: 0.0073 - accuracy: 0.9995 - val_loss: 0.4381 - val_accuracy: 0.8659\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 6s 211ms/step - loss: 0.0057 - accuracy: 0.9997 - val_loss: 0.4503 - val_accuracy: 0.8657\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 7s 221ms/step - loss: 0.0046 - accuracy: 0.9997 - val_loss: 0.4638 - val_accuracy: 0.8654\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 6s 212ms/step - loss: 0.0039 - accuracy: 0.9998 - val_loss: 0.4747 - val_accuracy: 0.8655\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 9s - loss: 0.4950 - accuracy: 0.8576\n",
      "[0.4949917495250702, 0.8575999736785889]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
